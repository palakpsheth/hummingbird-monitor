# .env.example
#
# Copy to .env and edit:
#   cp .env.example .env
#
# Notes:
# - This project is LAN-only and intentionally has no auth.
# - Keep .env private (Wyze credentials).
# - If using network_mode: host for wyze-bridge, HBMON_RTSP_URL usually points to your HOST LAN IP.

############################################
# Wyze Bridge (RTSP)
# Using IDisposable fork: https://github.com/IDisposable/docker-wyze-bridge
############################################

WYZE_EMAIL=you@example.com
WYZE_PASSWORD=your_password

# Optional: some Wyze accounts need a key / token depending on setup.
# If your wyze-bridge docs mention these, set them here (otherwise leave blank).
WYZE_API_KEY=
WYZE_API_ID=

# Optional: if you have 2FA or special auth modes, consult wyze-bridge docs
WYZE_MFA_TYPE=
WYZE_MFA_CODE=

# Optional: region override
WYZE_REGION=

# For your own reference (stream name you see in wyze-bridge UI)
WYZE_CAMERA_NAME=hummingbirdcam

# Stream quality setting for wyze-bridge (default: HD60)
# Options: SD30, SD60, HD30, HD60, 2K30, 2K60 (2K for supported cameras)
WYZE_QUALITY=HD30

############################################
# hbmon worker/web
############################################

# If wyze-bridge uses host networking, hbmon containers should reach it via host LAN IP:
# Example: rtsp://192.168.1.52:8554/hummingbirdcam?rtsp_transport=tcp
HBMON_RTSP_URL=rtsp://192.168.1.52:8554/hummingbirdcam
HBMON_RTSP_SNAPSHOT_URL=http://192.168.1.52:5000/snapshot/hummingbirdcam.jpg

HBMON_TITLE=Hummingbird Monitor
HBMON_CAMERA_NAME=hummingbirdcam

# Optional: footer commit label shown in the web UI.
# By default (when GIT_COMMIT is unset or set to "unknown"), the commit is detected automatically
# from git metadata. Setting GIT_COMMIT=unknown is equivalent to leaving it unset and keeps
# automatic detection enabled. This sets the GIT_COMMIT build arg which becomes HBMON_GIT_COMMIT
# inside the container. Uncomment and set a specific value only if you want to override automatic
# detection:
# GIT_COMMIT=abc1234

# Container paths (these map to ./data on host)
HBMON_DATA_DIR=/data
HBMON_MEDIA_DIR=/data/media
HBMON_CONFIG_PATH=/data/config.json

############################################
# Database + cache
############################################

# PostgreSQL connection string (async for web + worker)
HBMON_DB_ASYNC_URL=postgresql+asyncpg://hbmon:hbmon@hbmon-db:5432/hbmon

# Optional sync URL for tooling/tests (web/worker use async).
HBMON_DB_URL=postgresql+psycopg://hbmon:hbmon@hbmon-db:5432/hbmon

# Connection pool tuning
HBMON_DB_POOL_SIZE=5
HBMON_DB_MAX_OVERFLOW=10
HBMON_DB_POOL_TIMEOUT=30
HBMON_DB_POOL_RECYCLE=1800

# Redis cache (optional)
HBMON_REDIS_URL=redis://hbmon-redis:6379/0
HBMON_REDIS_TTL_SECONDS=5

# Web worker count for gunicorn
HBMON_WEB_WORKERS=4

# SQLite fallback tuning (only used if you override HBMON_DB_ASYNC_URL/HBMON_DB_URL to sqlite)
HBMON_SQLITE_BUSY_TIMEOUT_MS=5000

############################################
# Performance / detection tuning
############################################

HBMON_FPS_LIMIT=25

HBMON_DETECT_CONF=0.30
HBMON_DETECT_IOU=0.45
HBMON_MIN_BOX_AREA=600

HBMON_COOLDOWN_SECONDS=4

# Pre-trigger buffer for full visit recording (seconds before first detection)
# Captures frames before bird arrival for complete visit context
HBMON_ARRIVAL_BUFFER_SECONDS=5.0
# Seconds to wait after last detection before marking departure
HBMON_DEPARTURE_TIMEOUT_SECONDS=2.0
# Post-departure buffer for full visit recording
HBMON_POST_DEPARTURE_BUFFER_SECONDS=3.0

# Temporal voting window (frames) for stabilizing detections
HBMON_TEMPORAL_WINDOW_FRAMES=5
# Minimum frames within the temporal window that must contain a detection
HBMON_TEMPORAL_MIN_DETECTIONS=1

# Snapshot settings
HBMON_SNAPSHOT_TIMEOUT=10.0
HBMON_SNAPSHOT_RETRIES=10

############################################
# Species classification + re-ID tuning
############################################

HBMON_MIN_SPECIES_PROB=0.35

# Default model is BioCLIP (hf-hub:imageomics/bioclip).
# To switch back to OpenAI CLIP, set:
# HBMON_CLIP_MODEL=ViT-B-32
# HBMON_CLIP_PRETRAINED=openai
#
# To use another HF Hub model:
# HBMON_CLIP_MODEL=hf-hub:organization/model-name
# HBMON_CLIP_PRETRAINED=""

HBMON_CROP_PADDING=0.05
HBMON_MATCH_THRESHOLD=0.25
HBMON_EMA_ALPHA=0.10

# Quote this because it contains spaces and an apostrophe.
HBMON_SPECIES_LIST="Anna's Hummingbird,Allen's Hummingbird,Rufous Hummingbird,Costa's Hummingbird,Black-chinned Hummingbird,Calliope Hummingbird,Broad-billed Hummingbird,Rivoli's Hummingbird,Broad-tailed Hummingbird,Blue-throated Hummingbird,White-eared Hummingbird,Lucifer Hummingbird,Green Violetear,Hummingbird (unknown species)"
############################################
# Background subtraction (motion filtering)
############################################

# Enable/disable background subtraction for filtering detections
# Requires a background image to be configured via the /background UI
HBMON_BG_SUBTRACTION=1

# Pixel difference threshold (0-255) for detecting motion
# Lower = more sensitive, Higher = requires more significant change
HBMON_BG_MOTION_THRESHOLD=30

# Gaussian blur kernel size for noise reduction (must be an odd positive integer)
HBMON_BG_MOTION_BLUR=5

# Minimum fraction of detection area that must overlap with motion (0.0-1.0)
HBMON_BG_MIN_OVERLAP=0.15

# Debug logging for background subtraction (set to 1 to enable)
HBMON_DEBUG_BG=1

# Log motion-rejected detections as reviewable candidates
HBMON_BG_LOG_REJECTED=1

# Cooldown between logging rejected candidates (seconds)
HBMON_BG_REJECTED_COOLDOWN_SECONDS=3

# Save a short clip for rejected candidates (set to 1 to enable)
HBMON_BG_REJECTED_SAVE_CLIP=1

# Optional max candidates logged per minute (0 disables)
HBMON_BG_REJECTED_MAX_PER_MINUTE=30

# Save motion masks for observations/candidates
HBMON_BG_SAVE_MASKS=1

# Save mask overlay images (blended onto ROI frame)
HBMON_BG_SAVE_MASK_OVERLAY=1

# Mask image format (png recommended)
HBMON_BG_MASK_FORMAT=png

# Downscale masks to this max dimension (0 disables)
HBMON_BG_MASK_DOWNSCALE_MAX=0

############################################
# Video recording and streaming
############################################

# Videos are stored UNCOMPRESSED on disk to preserve quality for ML training.
# Compression is applied ON-THE-FLY when streaming to browsers.
# This provides the best of both worlds:
# - Pristine uncompressed videos for ML training/export
# - Efficient compressed streaming for browser playback
# - No duplicate storage

# Enable on-the-fly compression when streaming videos to browser (recommended)
# Set to 0 to stream uncompressed videos (larger bandwidth, slower loading)
HBMON_VIDEO_STREAM_COMPRESSION=1

# FFmpeg CRF (Constant Rate Factor) for streaming compression (18-28)
# Lower = better quality, larger stream size, more CPU
# 18: High quality (good for detailed review)
# 23: Default, balanced quality/bandwidth
# 28: Smaller stream, slightly reduced quality
HBMON_VIDEO_CRF=23

# FFmpeg encoding preset for streaming (speed vs compression tradeoff)
# Options: ultrafast, superfast, veryfast, faster, fast, medium, slow, slower, veryslow
# For on-the-fly streaming, faster presets reduce latency:
# - fast/veryfast: Quick compression, slightly larger files (recommended for streaming)
# - medium: Balanced
# - slow/slower: Better compression but adds latency
HBMON_VIDEO_PRESET=fast

# Path to FFmpeg binary (default: ffmpeg, uses system PATH)
HBMON_FFMPEG_PATH=ffmpeg

# Compressed video cache management
# Compressed videos are cached in /media/.cache/compressed/
# Max cache age in days (older files are removed)
HBMON_VIDEO_CACHE_MAX_AGE_DAYS=7

# Max cache size in GB (oldest files removed first when exceeded)
HBMON_VIDEO_CACHE_MAX_SIZE_GB=10.0

############################################
# Debugging / diagnostics
############################################

# Enable verbose logging for YOLO, classification, re-ID matching, and pipeline details
# Works with all backends (PyTorch, CUDA, OpenVINO CPU/GPU)
# Set to 1 to enable
HBMON_DEBUG_VERBOSE=1

# Save debug frames to disk (set to 1 to enable)
HBMON_DEBUG_SAVE_FRAMES=1

# Debug snapshot interval in seconds
HBMON_DEBUG_EVERY_SECONDS=30

# Override YOLO inference image size (H,W typical 1088,1920) or use "auto" to snap to ROI
HBMON_YOLO_IMGSZ=auto

############################################
# Hardware acceleration
############################################

# Unified inference backend for both YOLO and CLIP (recommended for most users)
# Options: "cpu" (PyTorch), "cuda", "openvino-cpu", "openvino-gpu"
# - "cpu": PyTorch CPU (default, works everywhere)
# - "openvino-cpu": OpenVINO CPU (1.5-2x faster, always available)
# - "openvino-gpu": OpenVINO Intel GPU (fastest for Intel iGPU/Arc, requires INSTALL_OPENVINO=1 build)
# - "cuda": NVIDIA GPU
# Note: Model conversion happens at worker startup (30-60 seconds first time)
# Recommendation: Use "openvino-cpu" for better CPU performance, or "openvino-gpu" if you have Intel GPU
HBMON_INFERENCE_BACKEND=cpu

# Advanced: Override YOLO backend separately (optional, takes priority over HBMON_INFERENCE_BACKEND)
# If set, this takes priority over HBMON_INFERENCE_BACKEND for YOLO only
# Options: pytorch, openvino-cpu, openvino-gpu, cuda
HBMON_YOLO_BACKEND=
# Example for Intel GPU: HBMON_YOLO_BACKEND=openvino-gpu

# Advanced: Override CLIP backend separately (optional)
# If set, this takes priority over HBMON_INFERENCE_BACKEND for CLIP only
HBMON_DEVICE=
# HBMON_DEVICE=openvino-cpu

# OpenVINO model cache directory (speeds up model loading on subsequent runs)
OPENVINO_CACHE_DIR=/data/openvino_cache

############################################
# YOLO model + config/cache directory
############################################

HBMON_YOLO_MODEL=yolo11s.pt
YOLO_CONFIG_DIR=/data/yolo

############################################
# Hugging Face (optional)
############################################
# Set this to avoid rate limits or access gated models
# The worker will automatically use it when downloading models via huggingface_hub
HF_TOKEN=

############################################
# Annotation Pipeline (Model Fine-Tuning)
############################################

# YOLO model for annotation preprocessing (high-accuracy option)
# Options: yolo11n.pt, yolo11s.pt, yolo11m.pt, yolo11l.pt, yolo11x.pt
# Larger models = more accurate but slower, use for annotation not real-time
HBMON_ANNOTATION_YOLO_MODEL=yolo11l.pt

# Enable SAM (Segment Anything Model) for precise box refinement
# SAM produces better bounding boxes from YOLO detections
# Requires ~2GB GPU memory, set to 0 to disable if GPU memory limited
HBMON_ANNOTATION_USE_SAM=1

# SAM model variant (sam_b, sam_l, sam_h ordered by size/accuracy)
# sam_b (base): 375MB, fastest, good accuracy
# sam_l (large): 1.2GB, slower, better accuracy
# sam_h (huge): 2.4GB, slowest, best accuracy
HBMON_ANNOTATION_SAM_MODEL=sam_b

# Detection confidence for annotation (lower than real-time to catch more)
HBMON_ANNOTATION_CONFIDENCE=0.15

# Batch size for frame processing (adjust based on GPU memory)
HBMON_ANNOTATION_BATCH_SIZE=8

# Enable background job queue for annotation preprocessing
HBMON_ANNOTATION_QUEUE_ENABLED=1

# Automatically extract frames for new observations
HBMON_ANNOTATION_AUTO_EXTRACT=0

# UTC hour for nightly batch processing (0-23)
HBMON_ANNOTATION_BATCH_HOUR=3

# Job timeouts (RQ format: 30m, 1h, etc.)
HBMON_ANNOTATION_EXTRACTION_TIMEOUT=30m
HBMON_ANNOTATION_DETECTION_TIMEOUT=60m
HBMON_ANNOTATION_PROPAGATION_TIMEOUT=5m

# Debug logging for annotator worker (set to 1 to enable)
HBMON_ANNOTATOR_DEBUG=1


# Retry and recovery configuration
HBMON_ANNOTATION_MAX_RETRIES=3
HBMON_ANNOTATION_RETRY_DELAY=60
HBMON_ANNOTATION_CHECKPOINT_INTERVAL=10

# Annotator resource limits (to prioritize main detection worker)
# System: 20 CPUs, 32GB RAM - leave headroom for main worker
HBMON_ANNOTATOR_CPU_LIMIT=4
HBMON_ANNOTATOR_MEMORY_LIMIT=8G
HBMON_ANNOTATOR_CPU_RESERVE=1
HBMON_ANNOTATOR_MEMORY_RESERVE=4G

# .env.example
#
# Copy to .env and edit:
#   cp .env.example .env
#
# Notes:
# - This project is LAN-only and intentionally has no auth.
# - Keep this file private (it contains Wyze credentials).
# - HBMON_RTSP_URL should point at the wyze-bridge container stream name.

############################################
# Wyze Bridge (RTSP)
############################################

# Your Wyze account credentials (required for wyze-bridge)
WYZE_EMAIL=your_email@example.com
WYZE_PASSWORD=your_password_here

# Optional: some Wyze accounts need a key / token depending on setup.
# If your wyze-bridge docs mention these, set them here (otherwise leave blank).
WYZE_API_KEY=
WYZE_API_ID=

# Optional: if you have 2FA or special auth modes, consult wyze-bridge docs.
# WYZE_MFA_TYPE=
# WYZE_MFA_CODE=

# Optional: region override (only if needed)
# WYZE_REGION=US

# Camera stream name as exposed by wyze-bridge (must match what you see in its UI)
# Example: hummingbirdcam
WYZE_CAMERA_NAME=hummingbirdcam

############################################
# hbmon worker/web
############################################

# RTSP URL that hbmon-worker will read.
# Because worker runs in docker compose, use the service name `wyze-bridge` as host:
HBMON_RTSP_URL=rtsp://wyze-bridge:8554/hummingbirdcam

# Display name stored with observations (optional)
HBMON_CAMERA_NAME=hummingbirdcam

# Where to store sqlite + config.json inside containers (docker volumes)
HBMON_DATA_DIR=/data
HBMON_MEDIA_DIR=/media

############################################
# Performance / detection tuning
############################################

# Worker loop throttle (approx max FPS read/detect). CPU sweet spot: 6â€“10
HBMON_FPS_LIMIT=8

# YOLO detector tuning
HBMON_DETECT_CONF=0.30
HBMON_DETECT_IOU=0.45
HBMON_MIN_BOX_AREA=600

# Cooldown between logged events (seconds)
HBMON_COOLDOWN_SECONDS=4

############################################
# Clip capture
############################################

# Clip length in seconds (current implementation is post-trigger)
HBMON_CLIP_SECONDS=2.5

############################################
# Species classification + re-ID tuning
############################################

# Minimum probability to accept a species label; otherwise set to "unknown"
HBMON_MIN_SPECIES_PROB=0.35

# Re-identification cosine distance threshold (lower=stricter, higher=more merging)
HBMON_MATCH_THRESHOLD=0.25

# Prototype update EMA alpha (lower=less drift, higher=adapts faster)
HBMON_EMA_ALPHA=0.10

############################################
# Hardware acceleration
############################################

# Device for CLIP (and potentially other torch models):
#   cpu (default) or cuda (if GPU is configured)
HBMON_DEVICE=cpu

############################################
# YOLO model choice
############################################

# Which ultralytics model to use. Larger models are slower but can improve detection.
# yolov8n.pt is fastest; try yolov8s.pt if you have CPU/GPU headroom.
HBMON_YOLO_MODEL=yolov8n.pt
